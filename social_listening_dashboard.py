# Shadee.Care â€“ Social Listening Dashboard (v9j)
# ---------------------------------------------------------------
# â€¢ Sidebar controls + ALLâ€‘sheet merge remain.
# â€¢ Fixes KeyError when a column is missing (e.g. no **Subreddit** column).
# â€¢ Guards all visualisations against empty data after filtering.
# ---------------------------------------------------------------

import re
import datetime as dt
from typing import Dict, List
from pathlib import Path

import pandas as pd
import streamlit as st
import praw

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATE_RE = re.compile(r"(\d{1,2}:\d{2})\s+(\d{1,2})\s+([A-Za-z]{3})\s+(\d{4})")
MON = {m: i for i, m in enumerate(
    ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"],
    1,
)}

def parse_post_date(txt: str):
    """Convert strings like 'Posted 05:44 13 Apr 2025' âžœÂ Datetime (UTCâ€‘naive) orÂ pd.NaT."""
    if not isinstance(txt, str):
        return pd.NaT
    m = DATE_RE.search(txt)
    if not m:
        return pd.NaT
    time_s, day, mon_s, year = m.groups()
    hh, mm = map(int, time_s.split(":"))
    try:
        return dt.datetime(int(year), MON[mon_s], int(day), hh, mm)
    except Exception:
        return pd.NaT

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  PageÂ setup & Reddit client (for future live mode)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="Shadee Live Listening", layout="wide")

if "reddit_api" not in st.session_state:
    if "reddit" in st.secrets:
        creds = st.secrets["reddit"]
        st.session_state.reddit_api = praw.Reddit(
            client_id=creds["client_id"],
            client_secret=creds["client_secret"],
            user_agent=creds["user_agent"],
            check_for_async=False,
        )
        st.write("ðŸ” Loaded client_id:", creds["client_id"])
        st.write("ðŸ” Loaded user_agent:", creds["user_agent"])
    st.warning("âš ï¸ Using anonymous (script) scopeÂ â€“ Reddit identity not fetched")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Buckets (regex)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BUCKET_PATTERNS: Dict[str, str] = {
    "self_blame": r"\b(hate(?:s|d)? (?:myself|me)|everyone hate(?:s|d)? me|worthless|i (?:don'?t|do not) deserve to live|i'?m a failure)\b",
    "cost_concern": r"\b(can'?t afford|too expensive|cost of therapy|insurance won'?t)\b",
    "work_burnout": r"\b(burnt out|burned out|toxic work|overworked|study burnout)\b",
    "self_harm": r"\b(kill myself|end my life|suicid(?:e|al)|self[- ]?harm)\b",
    "relationship_breakup": r"\b(break[- ]?up|dump(?:ed)?|heart ?broken|lost my (?:partner|girlfriend|boyfriend))\b",
    "friendship_drama": r"\b(friend(?:ship)? (?:ignore(?:d)?|ghost(?:ed)?|lost)|no friends?)\b",
    "crying_distress": r"\b(can'?t stop crying|keep on crying)\b",
}
COMPILED: Dict[str, re.Pattern] = {n: re.compile(p, re.I) for n, p in BUCKET_PATTERNS.items()}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Sidebar controls
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.title("ðŸ“Š Choose Data Source")
mode = st.sidebar.radio("Select mode", ("Upload Excel", "Live Reddit Pull"), index=0)

xl_file = st.sidebar.file_uploader("DragÂ &Â drop Excel", type="xlsx")
sheet_name = None
if xl_file:
    with pd.ExcelFile(xl_file) as xls:
        sheets = xls.sheet_names
    sheet_name = st.sidebar.selectbox("Sheet", ["ALL"] + sheets, index=0)

# dateâ€‘range (last 30Â days by default)
end_d = dt.date.today()
start_d = end_d - dt.timedelta(days=30)
sel_range = st.sidebar.date_input("Select Date Range", (start_d, end_d))
if isinstance(sel_range, tuple):
    start_d, end_d = sel_range

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Excelâ€‘processing path
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if mode == "Upload Excel" and xl_file:
    dfs: List[pd.DataFrame] = []
    xl = pd.ExcelFile(xl_file)
    targets = xl.sheet_names if sheet_name == "ALL" else [sheet_name]
    for s in targets:
        df_s = xl.parse(s, skiprows=2)  # first two rows are header meta
        if "Post Date" not in df_s.columns or "Post Content" not in df_s.columns:
            st.error(f"âŒ Required columns missing in sheet â€˜{s}â€™. Skipped.")
            continue
        df_s["Post_dt"] = df_s["Post Date"].map(parse_post_date)
        df_s["Platform"] = df_s["Platform"].str.lower().fillna("unknown")
        dfs.append(df_s)
    if not dfs:
        st.stop()
    df = pd.concat(dfs, ignore_index=True)

    # date filter
    mask = (df["Post_dt"].dt.date >= start_d) & (df["Post_dt"].dt.date <= end_d)
    df = df.loc[mask].copy()

    # bucket tagging
    def tag_bucket(text: str):
        if not isinstance(text, str):
            return "other"
        for n, cre in COMPILED.items():
            if cre.search(text):
                return n
        return "other"

    df["Bucket"] = df["Post Content"].apply(tag_bucket)

    # after buckets â†’ filter list
    sel_buckets = st.sidebar.multiselect(
        "Select buckets", sorted(df["Bucket"].unique()), default=list(sorted(df["Bucket"].unique()))
    )
    df = df[df["Bucket"].isin(sel_buckets)]

    st.success(f"âœ… {len(df)} posts after filtering")

    if df.empty:
        st.warning("No rows match the current filters.")
        st.stop()

    # â”€â”€ charts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.subheader("ðŸ“Š Post volume by bucket")
    st.bar_chart(df["Bucket"].value_counts())

    st.subheader("ðŸ“ˆ Post trend over time")
    trend = (
        df.set_index("Post_dt").resample("1D").size().loc[start_d:end_d]
    )
    st.line_chart(trend)

    st.subheader("ðŸ§  Top subreddits")
    if "Subreddit" in df.columns:
        top_sub = df["Subreddit"].fillna("Unknown").value_counts().head(10)
        st.bar_chart(top_sub)
    else:
        st.info("Subreddit column not present in this dataset.")

    st.subheader("ðŸ“„ Content sample")
    subset_cols = [c for c in ["Post_dt", "Bucket", "Subreddit", "Post Content"] if c in df.columns]
    st.dataframe(df[subset_cols].head(50), height=300)

elif mode == "Live Reddit Pull":
    st.info("ðŸ”§ Live mode not yet wired â€“Â stay tuned!")
else:
    st.warning("â¬…ï¸ Upload an Excel file on the left to begin")
